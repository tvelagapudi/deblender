{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model Assisted GAN Lensing",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tvelagapudi/deblender/blob/master/Model_Assisted_GAN_Lensing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExY0qlU0BqfZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "7639a5b2-f5cd-4763-b314-e032d3c2e44a"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Activation, Flatten, Reshape\n",
        "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
        "from keras.layers import LeakyReLU, Dropout, BatchNormalization, Lambda\n",
        "from keras.optimizers import Adam, RMSprop, SGD\n",
        "from keras import initializers\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "!pip install import-ipynb\n",
        "import import_ipynb\n",
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Copy the link and remove the front part of the link (i.e. https://drive.google.com/open?id=) to get the file ID.\n",
        "your_module = drive.CreateFile({'id':'1F4Q9K86uZVRlou1ieNxohZEk5-vHZwIB'})\n",
        "your_module.GetContentFile('lenstronomy1.ipynb')\n",
        "import lenstronomy1 as lens"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: import-ipynb in /usr/local/lib/python3.6/dist-packages (0.1.3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0709 15:11:03.742194 140635728914304 __init__.py:44] file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
            "    from google.appengine.api import memcache\n",
            "ModuleNotFoundError: No module named 'google.appengine'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
            "    from oauth2client.contrib.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
            "    from oauth2client.locked_file import LockedFile\n",
            "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
            "    from . import file_cache\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
            "    'file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth')\n",
            "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0 or google-auth\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tlNEcKiLJJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Networks(object):\n",
        "    def __init__(self, noise_size=100, params=4, img_rows=28, img_cols=28, channel=1):\n",
        "        self.noise_size = noise_size\n",
        "        self.params = params\n",
        "        self.img_rows = img_rows\n",
        "        self.img_cols = img_cols\n",
        "        self.channel = channel\n",
        "        self.G = None # generator\n",
        "        self.E = None # emulator\n",
        "        self.D = None # discriminator\n",
        "        self.S = None # siamese\n",
        "        self.GE = None # generator + emulator\n",
        "        self.SM = None # siamese model\n",
        "        self.AM1 = None # adversarial model 1\n",
        "        self.DM = None # discriminator model\n",
        "        self.AM2 = None # adversarial model 2\n",
        "    \n",
        "    '''\n",
        "    Generator: produce parameters such that the simulator can use them to create images that \n",
        "    cannot be distinguished from true data images\n",
        "    '''\n",
        "    def generator(self):\n",
        "        if self.G:\n",
        "            return self.G\n",
        "        \n",
        "        # params\n",
        "        dropout = 0.0\n",
        "        depth = 64\n",
        "        dim = 7\n",
        "        \n",
        "        # input noise\n",
        "        input_noise_shape = (self.noise_size,)\n",
        "        input_noise_layer = Input(shape=input_noise_shape, name='input_noise')\n",
        "        \n",
        "        # architecture\n",
        "        self.G = Dense(dim*dim*depth)(input_noise_layer)\n",
        "        \n",
        "        #self.G = BatchNormalization(momentum=0.9)(self.G)\n",
        "        self.G = LeakyReLU(0.2)(self.G)\n",
        "        self.G = Dense(dim*depth)(self.G)\n",
        "        \n",
        "        #self.G = BatchNormalization(momentum=0.9)(self.G)\n",
        "        self.G = LeakyReLU(0.2)(self.G)\n",
        "        self.G = Dropout(dropout)(self.G)\n",
        "        self.G = Dense(self.params, activation='tanh')(self.G)\n",
        "        \n",
        "        # model\n",
        "        self.G = Model(inputs=input_noise_layer, outputs=self.G, name='generator')\n",
        "        \n",
        "        # print\n",
        "        print(\"Generator:\")\n",
        "        self.G.summary()\n",
        "        return self.G\n",
        "\n",
        "    ''' \n",
        "    Emulator: generate identical images to those of the simulator S when both E and S \n",
        "    are fed with the same input parameters\n",
        "    ''' \n",
        "    def emulator(self):\n",
        "        if self.E:\n",
        "            return self.E\n",
        "\n",
        "        # input params\n",
        "        input_params_shape = (self.params,)\n",
        "        input_params_layer = Input(shape=input_params_shape, name='input_params')\n",
        "\n",
        "        # architecture\n",
        "        self.E = Dense(1024)(input_params_layer)\n",
        "        self.E = LeakyReLU(0.2)(self.E)\n",
        "        self.E = Dense(7*7*128, kernel_initializer=initializers.RandomNormal(stddev=0.02))(self.E)\n",
        "        self.E = LeakyReLU(0.2)(self.E)\n",
        "        self.E = Reshape((7, 7, 128))(self.E)\n",
        "        self.E = UpSampling2D(size=(2, 2))(self.E)\n",
        "        self.E = Conv2D(64, kernel_size=(5, 5), padding='same')(self.E)\n",
        "        self.E = LeakyReLU(0.2)(self.E)\n",
        "        self.E = UpSampling2D(size=(2, 2))(self.E)\n",
        "        self.E = Conv2D(1, kernel_size=(5, 5), padding='same', activation='tanh')(self.E)\n",
        "\n",
        "        # model\n",
        "        self.E = Model(inputs=input_params_layer, outputs=self.E, name='emulator')\n",
        "\n",
        "        # print\n",
        "        print(\"Emulator\")\n",
        "        self.E.summary()\n",
        "        return self.E\n",
        "\n",
        "    '''\n",
        "    Discriminator: distinguish between true data images and images produced by the simulator (or \n",
        "    images produced by the emulator to speed up the training process)\n",
        "    '''\n",
        "    def discriminator(self):\n",
        "        if self.D:\n",
        "            return self.D\n",
        "\n",
        "        # input image\n",
        "        input_shape_image = (self.img_rows, self.img_cols, self.channel)\n",
        "        input_layer_image = Input(shape=input_shape_image, name='input_image')\n",
        "        \n",
        "        # architecture\n",
        "        self.D = Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding='same', \n",
        "                        kernel_initializer=initializers.RandomNormal(stddev=0.02))(input_layer_image)\n",
        "        self.D = LeakyReLU(0.2)(self.D)\n",
        "        self.D = Dropout(0.3)(self.D)\n",
        "        self.D = Conv2D(128, kernel_size=(5, 5), strides=(2, 2), padding='same')(self.D)\n",
        "        self.D = LeakyReLU(0.2)(self.D)\n",
        "        self.D = Dropout(0.3)(self.D)\n",
        "        self.D = Flatten()(self.D)\n",
        "        self.D = Dense(1)(self.D)\n",
        "        self.D = Activation('sigmoid')(self.D)\n",
        "\n",
        "        # model\n",
        "        self.D = Model(inputs=input_layer_image, outputs=self.D, name='discriminator')\n",
        "\n",
        "        # print\n",
        "        print(\"Discriminator:\")\n",
        "        self.D.summary()\n",
        "        return self.D\n",
        "\n",
        "    '''\n",
        "    Siamese: determine the similarity between images produced by the simulator and the emulator\n",
        "    '''\n",
        "    def siamese(self):\n",
        "        if self.S:\n",
        "            return self.S\n",
        "\n",
        "        # input images\n",
        "        input_shape_image = (self.img_rows, self.img_cols, self.channel)\n",
        "        input_image_anchor = Input(shape=input_shape_image, name='input_image_anchor')\n",
        "        input_image_candid = Input(shape=input_shape_image, name='input_image_candidate')\n",
        "        input_image = Input(shape=input_shape_image, name='input_image')\n",
        "\n",
        "        # siamese\n",
        "        cnn = Conv2D(64, kernel_size=(8, 8), strides=(2, 2), padding='same', \n",
        "                     kernel_initializer=initializers.RandomNormal(stddev=0.02))(input_image)\n",
        "        cnn = LeakyReLU(0.2)(cnn)\n",
        "        #cnn = Dropout(0.3)(cnn)\n",
        "        cnn = Conv2D(128, kernel_size=(5, 5), strides=(2, 2), padding='same')(cnn)\n",
        "        cnn = LeakyReLU(0.2)(cnn)\n",
        "        #cnn = Dropout(0.3)(cnn)\n",
        "        cnn = Flatten()(cnn)\n",
        "        cnn = Dense(128, activation='sigmoid')(cnn)\n",
        "        cnn = Model(inputs=input_image, outputs=cnn, name='cnn')\n",
        "\n",
        "        # left and right encodings         \n",
        "        encoded_l = cnn(input_image_anchor)\n",
        "        encoded_r = cnn(input_image_candid)\n",
        "\n",
        "        # merge two encoded inputs with the L1 or L2 distance between them\n",
        "        L1_distance = lambda x: K.abs(x[0]-x[1])\n",
        "        L2_distance = lambda x: (x[0]-x[1]+K.epsilon())**2/(x[0]+x[1]+K.epsilon())\n",
        "        both = Lambda(L2_distance)([encoded_l, encoded_r])\n",
        "        prediction = Dense(1, activation='sigmoid')(both)\n",
        "\n",
        "        # model\n",
        "        self.S = Model([input_image_anchor, input_image_candid], output=prediction, name='siamese')\n",
        "\n",
        "        # print\n",
        "        print(\"Siamese:\")\n",
        "        self.S.summary()\n",
        "        return self.S\n",
        "\n",
        "    '''\n",
        "    Generator + emulator: output emulated images from input noise\n",
        "    '''\n",
        "\n",
        "    def generator_emulator(self):\n",
        "        if self.GE:\n",
        "            return self.GE\n",
        "\n",
        "        # input noise\n",
        "        input_noise_shape = (self.noise_size,)\n",
        "        input_noise_layer = Input(shape=input_noise_shape, name='input_noise') \n",
        "\n",
        "        # generator\n",
        "        generator_ref = self.generator()\n",
        "        generator_ref.trainable = False\n",
        "        self.GE = generator_ref(input_noise_layer)\n",
        "\n",
        "        # emulator\n",
        "        emulator_ref = self.emulator()\n",
        "        emulator_ref.trainable = False\n",
        "        self.GE = emulator_ref(self.GE)\n",
        "\n",
        "        # model\n",
        "        self.GE = Model(inputs=input_noise_layer, outputs=self.GE, name='generator_emulator')\n",
        "\n",
        "        # print\n",
        "        print(\"Generator + Emulator:\")\n",
        "        self.GE.summary()\n",
        "        return self.GE\n",
        "\n",
        "    '''\n",
        "    Discriminator model\n",
        "    '''\n",
        "    def discriminator_model(self):\n",
        "        if self.DM:\n",
        "            return self.DM\n",
        "          \n",
        "        # optimizer\n",
        "        #optimizer = SGD(lr=0.0001)\n",
        "        optimizer = Adam(lr=0.0001)\n",
        "\n",
        "        # input image\n",
        "        input_image_shape = (self.img_rows, self.img_cols, self.channel)\n",
        "        input_image_layer = Input(shape=input_image_shape, name='input_image')\n",
        "\n",
        "        # discriminator\n",
        "        discriminator_ref = self.discriminator()\n",
        "        discriminator_ref.trainable = True\n",
        "        self.DM = discriminator_ref(input_image_layer)\n",
        "\n",
        "        # model\n",
        "        self.DM = Model(inputs=input_image_layer, outputs=self.DM, name='discriminator_model')\n",
        "        self.DM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
        "            metrics=['accuracy'])\n",
        "        print(\"Discriminator model\") \n",
        "        self.DM.summary()\n",
        "        return self.DM\n",
        "\n",
        "    '''\n",
        "    Siamese model\n",
        "    '''\n",
        "    def siamese_model(self):\n",
        "        if self.SM:\n",
        "            return self.SM\n",
        "\n",
        "        # optimizer\n",
        "        #optimizer = SGD(lr=0.0001)\n",
        "        optimizer = Adam(lr=0.0001)\n",
        "\n",
        "        # input images\n",
        "        input_shape_image = (self.img_rows, self.img_cols, self.channel)\n",
        "        input_image_anchor = Input(shape=input_shape_image, name='input_image_anchor')\n",
        "        input_image_candid = Input(shape=input_shape_image, name='input_image_candidate')\n",
        "        input_layer = [input_image_anchor, input_image_candid]\n",
        "\n",
        "        # discriminator\n",
        "        siamese_ref = self.siamese()\n",
        "        siamese_ref.trainable = True\n",
        "        self.SM = siamese_ref(input_layer)\n",
        "\n",
        "        # model\n",
        "        self.SM = Model(inputs=input_layer, outputs=self.SM, name='siamese_model')\n",
        "        self.SM.compile(loss='binary_crossentropy', optimizer=optimizer,\\\n",
        "            metrics=['accuracy'])\n",
        "        \n",
        "        #print\n",
        "        print(\"Siamese model\") \n",
        "        self.SM.summary()\n",
        "        return self.SM\n",
        "\n",
        "    '''\n",
        "    Adversarial 1 model\n",
        "    '''\n",
        "    def adversarial1_model(self):\n",
        "        if self.AM1:\n",
        "            return self.AM1\n",
        "         \n",
        "        #optimizer\n",
        "        optimizer = Adam(lr=0.0001)\n",
        "\n",
        "        # input 1: simulated image\n",
        "        input_image_shape = (self.img_rows, self.img_cols, self.channel)\n",
        "        input_image_layer = Input(shape=input_image_shape, name='input_image')\n",
        "\n",
        "        # input 2: params\n",
        "        input_params_shape = (self.params,)\n",
        "        input_params_layer = Input(shape=input_params_shape, name='input_params')\n",
        "\n",
        "        # emulator\n",
        "        emulator_ref = self.emulator()\n",
        "        emulator_ref.trainable = True\n",
        "        self.AM1 = emulator_ref(input_params_layer)\n",
        "\n",
        "        # siamese\n",
        "        siamese_ref = self.siamese()\n",
        "        siamese_ref.trainable = False\n",
        "        self.AM1 = siamese_ref([input_image_layer, self.AM1])\n",
        "\n",
        "        # model\n",
        "        input_layer = [input_image_layer, input_params_layer] \n",
        "        self.AM1 = Model(inputs=input_layer, outputs=self.AM1, name='adversarial_1_model')\n",
        "        self.AM1.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "        # print\n",
        "        print(\"Adversarial 1 model:\")\n",
        "        self.AM1.summary()\n",
        "        return self.AM1\n",
        "\n",
        "    '''\n",
        "    Adversarial 2 model\n",
        "    '''\n",
        "\n",
        "    def adversarial2_model(self):\n",
        "        if self.AM2:\n",
        "            return self.AM2\n",
        "          \n",
        "        #optimizer\n",
        "        optimizer = Adam(lr=0.0001)\n",
        "\n",
        "        # input noise\n",
        "        input_noise_shape = (self.noise_size,)\n",
        "        input_noise_layer = Input(shape=input_noise_shape, name='input_noise')\n",
        "\n",
        "        # generator\n",
        "        generator_ref = self.generator()\n",
        "        generator_ref.trainable = True\n",
        "        self.AM2 = generator_ref(input_noise_layer)\n",
        "\n",
        "        # emulator\n",
        "        emulator_ref = self.emulator(\n",
        "        emulator_ref.trainable = False\n",
        "        self.AM2 = emulator_ref(self.AM2)\n",
        "\n",
        "        # discriminator\n",
        "        discriminator_ref = self.discriminator()\n",
        "        discriminator_ref.trainable = False\n",
        "        self.AM2 = discriminator_ref(self.AM2)\n",
        "\n",
        "        # model\n",
        "        self.AM2 = Model(inputs=input_noise_layer, outputs=self.AM2, name='adversarial_2_model')\n",
        "        self.AM2.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "        # print\n",
        "        print(\"Adversarial 2 model\")\n",
        "        self.AM2.summary()\n",
        "        return self.AM2\n",
        "\n",
        "\n",
        "# manually specify the GPUs to use\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
        "\n",
        "# remove for randomness\n",
        "np.random.seed(7)\n",
        "net_range  = [-1,1]\n",
        "\n",
        "# Case study 1 ranges and mapping\n",
        "m_range = [-2,2]\n",
        "b_range = [-2,2]\n",
        "x_range = [0,12]\n",
        "l_range = [5,15]\n",
        "m_m = interp1d(net_range,m_range)\n",
        "m_b = interp1d(net_range,b_range)\n",
        "m_x = interp1d(net_range,x_range)\n",
        "m_l = interp1d(net_range,l_range)\n",
        "\n",
        "# Case study 2 ranges and mapping\n",
        "x0_range = [5,23]\n",
        "y0_range = [5,23]\n",
        "r_range  = [2,14]\n",
        "n_range  = [0,0.5]\n",
        "b_range  = [0.5,1]\n",
        "m_x0 = interp1d(net_range,x0_range)\n",
        "m_y0 = interp1d(net_range,y0_range)\n",
        "m_r  = interp1d(net_range,r_range)\n",
        "m_n  = interp1d(net_range,n_range)\n",
        "m_b  = interp1d(net_range,b_range)\n",
        "\n",
        "class ModelAssistedGAN(object):\n",
        "    # Output parameters for true data\n",
        "    def data_params(self, cs='cs1'):\n",
        "        \n",
        "        # Case study 1\n",
        "        if cs=='cs1':\n",
        "            while(True):\n",
        "                m, b, x0, length = [np.random.normal(1.5, 0.3, 1)[0], np.random.normal(0.5, 0.1, 1)[0], \n",
        "                                    np.random.normal(10, 0.5, 1)[0], np.random.normal(9, 0.5, 1)[0]]\n",
        "                y = int(round(m*x0+b))\n",
        "                if y >= -(self.img_rows//2) and y<(self.img_rows//2):\n",
        "                    break\n",
        "            return m, b, x0, length\n",
        "\n",
        "        # Case study 2\n",
        "        x0, y0, r, n, b = [np.random.normal(18, 0.8, 1)[0], np.random.normal(18, 0.8, 1)[0],\n",
        "                           np.random.normal(8, 0.5, 1)[0], np.random.normal(0.15, 0.05, 1)[0], \n",
        "                           np.random.normal(0.9, 0.05, 1)[0]]\n",
        "        return x0, y0, r, n, b\n",
        "    \n",
        "    # Fill pixel map for case study 1 \n",
        "    \"\"\"def fillPixelMapCS1(self, m, b, x0, length, pixelMap):\n",
        "        max_len = pixelMap.shape[0]\n",
        "        value = 1.0\n",
        "        x0 = int(round(float(x0)))\n",
        "        length = int(round(float(length))) \n",
        "        for x in range(x0, x0+length):\n",
        "            if x >= max_len or x < 0:\n",
        "                continue\n",
        "            y=int(round(m*x+b))+max_len//2\n",
        "            if y >= max_len or y < 0:\n",
        "                continue\n",
        "            pixelMap[x,y,0]=value\n",
        "\n",
        "    # Fill pixel map for case study 2\n",
        "    def fillPixelMapCS2(self, x0, y0, r, n, b, pixelMap):\n",
        "        def putpixel(self, x, y, b, pixelMap):\n",
        "            if x>=0 and y>=0 and x<pixelMap.shape[0] and y<pixelMap.shape[1]:\n",
        "                pixelMap[x,y,0] = max(min(np.random.normal((2*b)-1, 0.05, 1)[0], 1.0), -1.0)\n",
        "        x0 = int(round(x0))\n",
        "        y0 = int(round(y0))\n",
        "        r  = int(round(r))\n",
        "        x = r-1\n",
        "        y = 0\n",
        "        dx = 1\n",
        "        dy = 1\n",
        "        err = dx - (r << 1)\n",
        "        \n",
        "        # noise\n",
        "        for row in range(pixelMap.shape[0]):\n",
        "            for col in range(pixelMap.shape[1]):\n",
        "                pixelMap[row, col, 0] = max(min(np.random.normal((2*n)-1, 0.05, 1)[0], 1.0), -1.0)\n",
        "\n",
        "        # signal\n",
        "        while (x >= y):\n",
        "            putpixel(x0 + x, y0 + y, b, pixelMap)\n",
        "            putpixel(x0 + y, y0 + x, b, pixelMap)\n",
        "            putpixel(x0 - y, y0 + x, b, pixelMap)\n",
        "            putpixel(x0 - x, y0 + y, b, pixelMap)\n",
        "            putpixel(x0 - x, y0 - y, b, pixelMap)\n",
        "            putpixel(x0 - y, y0 - x, b, pixelMap)\n",
        "            putpixel(x0 + y, y0 - x, b, pixelMap)\n",
        "            putpixel(x0 + x, y0 - y, b, pixelMap)\n",
        "            if (err <= 0):\n",
        "                y+=1\n",
        "                err += dy\n",
        "                dy += 2\n",
        "            if (err > 0):\n",
        "                x-=1\n",
        "                dx += 2\n",
        "                err += dx - (r << 1)\"\"\"\n",
        "\n",
        "    def __init__(self, noise_size=100, params=4, img_rows=28, img_cols=28, channel=1):\n",
        "        self.noise_size = noise_size\n",
        "        self.params = params\n",
        "        self.img_rows = img_rows\n",
        "        self.img_cols = img_cols\n",
        "        self.channel = channel\n",
        "        self.Networks = Networks(noise_size=noise_size, params=params, img_rows=img_rows, \n",
        "                        img_cols=img_cols, channel=channel)\n",
        "        self.discriminator = self.Networks.discriminator_model()\n",
        "        self.siamese = self.Networks.siamese_model()\n",
        "        self.adversarial1 = self.Networks.adversarial1_model()\n",
        "        self.adversarial2 = self.Networks.adversarial2_model()\n",
        "        self.generator = self.Networks.generator()\n",
        "        self.generator_emulator = self.Networks.generator_emulator()\n",
        "        self.emulator = self.Networks.emulator()\n",
        "\n",
        "    def train(self, train_steps=100000, batch_size=128):\n",
        "        '''\n",
        "        Pre-training stage\n",
        "        '''\n",
        "        for train_step in range(train_steps):\n",
        "            log_mesg = '%d:' % train_step\n",
        "            noise_value = 0.05\n",
        "            params_list = np.random.uniform(-1.0, 1.0, size=[batch_size, self.params])\n",
        "            y_ones = np.ones([batch_size, 1])\n",
        "            y_zeros = np.zeros([batch_size, 1])\n",
        "\n",
        "            '''\n",
        "            Step 1\n",
        "            '''\n",
        "            \n",
        "            # simulated images\n",
        "            images_simu = np.zeros((batch_size, self.img_rows,self.img_cols,self.channel))\n",
        "            images_simu.fill(-1)\n",
        "            # commented lines (case study 2)\n",
        "            #images_simu2 = np.zeros((batch_size, self.img_rows,self.img_cols,self.channel)) # case study 2\n",
        "            #images_simu2.fill(-1) # case study 2\n",
        "            for index in range(batch_size):\n",
        "                m, b, x0, length = params_list[index]\n",
        "                self.fillPixelMapCS1(m_m(m), m_b(b), m_x(x0), m_l(length), images_simu[index])\n",
        "                # commented lines (case study 2)\n",
        "                #x0, y0, r, n, b = params_list[index]\n",
        "                #self.fillPixelMapCS2(m_x0(x0), m_y0(y0), m_r(r), m_n(n), m_b(b), images_simu[index])\n",
        "                #self.fillPixelMapCS2(m_x0(x0), m_y0(y0), m_r(r), m_n(n), m_b(b), images_simu2[index])\n",
        "            images_simu_copy = np.copy(images_simu)\n",
        "            # commented lines (case study 2)\n",
        "            #images_simu2_copy = np.copy(images_simu2)\n",
        "\n",
        "            # emulated images\n",
        "            images_emul = self.emulator.predict(params_list)\n",
        "            images_emul_copy = np.copy(images_emul)\n",
        "\n",
        "            # noise\n",
        "            y_ones = np.array([np.random.uniform(0.7,1.0) for x in range(batch_size)]).reshape([batch_size, 1])\n",
        "            y_zeros = np.array([np.random.uniform(0,0.3) for x in range(batch_size)]).reshape([batch_size, 1])\n",
        "            if noise_value > 0:\n",
        "                for index in range(batch_size):\n",
        "                    if np.random.random() < noise_value:\n",
        "                        images_simu_copy[index], images_emul_copy[index] = images_emul[index], images_simu[index]\n",
        "\n",
        "\n",
        "            # train siamese\n",
        "            d_loss_simu = self.siamese.train_on_batch([images_simu_copy, images_simu_copy], y_ones)\n",
        "            # commented lines (case study 2)\n",
        "            #d_loss_simu = self.siamese.train_on_batch([images_simu_copy, images_simu2_copy], y_ons)\n",
        "            d_loss_fake = self.siamese.train_on_batch([images_simu_copy, images_emul_copy], y_zeros)\n",
        "            d_loss = 0.5 * np.add(d_loss_simu, d_loss_fake)\n",
        "            log_mesg = \"%s [S loss: %f]\" % (log_mesg, d_loss[0])\n",
        "\n",
        "            '''\n",
        "            Step 2\n",
        "            '''\n",
        "\n",
        "            #for index in range(batch_size):\n",
        "            #    if np.random.random() < noise_value:\n",
        "            #        y_ones[index, 0] = np.random.uniform(0,0.3)\n",
        "            y_ones = np.ones([batch_size, 1])\n",
        "\n",
        "            # train emulator\n",
        "            a_loss = self.adversarial1.train_on_batch([images_simu, params_list], y_ones)\n",
        "            log_mesg = \"%s [E loss: %f]\" % (log_mesg, a_loss[0])\n",
        "            print(log_mesg)\n",
        "\n",
        "        '''\n",
        "        Training stage\n",
        "        '''\n",
        "        for train_step in range(train_steps):\n",
        "            log_mesg = '%d:' % train_step\n",
        "            noise_value = 0.3\n",
        "            noise = np.random.uniform(-1.0, 1.0, size=[batch_size, self.noise_size])\n",
        "            params_list = self.generator.predict(noise)\n",
        "            y_ones = np.ones([batch_size, 1])\n",
        "            y_zeros = np.zeros([batch_size, 1])\n",
        "            \n",
        "            '''\n",
        "            Step 1\n",
        "            '''\n",
        "            \n",
        "            # true images\n",
        "            images_true = np.zeros((batch_size, self.img_rows, self.img_cols, self.channel))\n",
        "            images_true.fill(-1)       \n",
        "            for index in range(batch_size):\n",
        "                m, b, x0, length = self.data_params()\n",
        "                self.fillPixelMapCS1(m, b, x0, length, images_true[index])\n",
        "                # commented lines (case study 2)\n",
        "                #x0, y0, r, n, b = params_list[index]\n",
        "                #self.fillPixelMapCS2(m_x0(x0), m_y0(y0), m_r(r), m_n(n), m_b(b), images_true[index])\n",
        "            images_true_copy = np.copy(images_true) \n",
        "\n",
        "            # simulated images\n",
        "            images_simu = np.zeros((batch_size, self.img_rows,self.img_cols, self.channel))\n",
        "            images_simu.fill(-1)\n",
        "            for index in range(batch_size):\n",
        "                m, b, x0, length = params_list[index]\n",
        "                self.fillPixelMapCS1(m_m(m), m_b(b), m_x(x0), m_l(length), images_simu[index])\n",
        "                # commented lines (case study 2)\n",
        "                #x0, y0, r, n, b = params_list[index]\n",
        "                #self.fillPixelMapCS2(m_x0(x0), m_y0(y0), m_r(r), m_n(n), m_b(b), images_simu[index])\n",
        "            images_simu_copy = np.copy(images_simu)\n",
        "\n",
        "            # noise\n",
        "            y_ones = np.array([np.random.uniform(0.7,1.2) for x in range(batch_size)]).reshape([batch_size, 1])\n",
        "            y_zeros = np.array([np.random.uniform(0,0.3) for x in range(batch_size)]).reshape([batch_size, 1])\n",
        "            if np.random.random() < noise_value:\n",
        "                for index in range(batch_size):\n",
        "                    if np.random.random() < noise_value:\n",
        "                        images_true_copy[index], images_simu_copy[index] = images_simu[index], images_true[index]\n",
        "\n",
        "            # train discriminator\n",
        "            d_loss_true = self.discriminator.train_on_batch(images_true_copy, y_ones)\n",
        "            d_loss_simu = self.discriminator.train_on_batch(images_simu_copy, y_zeros)\n",
        "            d_loss = 0.5 * np.add(d_loss_true, d_loss_simu)\n",
        "            log_mesg = \"%s [D loss: %f]\" % (log_mesg, d_loss[0])\n",
        "\n",
        "            '''\n",
        "            Step 2\n",
        "            '''\n",
        "\n",
        "            # noise\n",
        "            for index in range(batch_size):\n",
        "                if np.random.random() < noise_value:\n",
        "                    y_ones[index, 0] = np.random.uniform(0,0.3)\n",
        "\n",
        "            # train generator\n",
        "            a_loss = self.adversarial2.train_on_batch(noise, y_ones)\n",
        "            log_mesg = \"%s [G loss: %f]\" % (log_mesg, a_loss[0])\n",
        "            print(log_mesg)\n",
        "            noise_value*=0.999\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    noise_size=100\n",
        "    params=4\n",
        "    img_rows=28\n",
        "    img_cols=28\n",
        "    channel=1\n",
        "    magan = ModelAssistedGAN(noise_size=noise_size, params=params, img_rows=img_rows, img_cols=img_cols,\n",
        "                             channel=channel)\n",
        "    magan.train(train_steps=500000, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}